<!doctype html>

<head>
    <title>Sistine</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="stylesheet" href="/css/main.css">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;700&family=Newsreader:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">

    <!-- Facebook Open Graph tags -->
    <meta property="og:url" content="https://sistine.vercel.app" />
    <meta property="og:title" content="Sistine, the static site engine" />
    <meta property="og:description" content="A simple, flexible, productive static site engine written in Ink" />
    <meta property="og:image" content="https://sistine.vercel.app/img/sistine-screenshot.png" />

    <!-- Twitter Card (large image card) tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@thesephist">
    <meta name="twitter:title" content="Sistine, the static site engine">
    <meta name="twitter:description" content="A simple, flexible, productive static site engine written in Ink" />
    <meta name="twitter:image" content="https://sistine.vercel.app/img/sistine-screenshot.png" />
</head>


<body>
<main>
    <header>
    <nav class="left-nav">
        <a href="/"><strong>Sistine</strong></a>
        <a href="/docs/">Docs</a>
        <a href="/start/">Get started</a>
    </nav>
    <nav class="right-nav">
        <a href="https://github.com/thesephist/sistine">GitHub</a>
    </nav>
</header>


    <article>
        

        
        <p>#article</p><p>[[data/Изучить статистику]]</p><h1>А главное зачем</h1><p>Статистика не так уж далека от жизни. С ее помощью исследуют что-либо, что сложно описать и проще использовать вероятностные методы. Например, для исследования эффективности лекарства, можно проследить все химически и биологические реакции организма на это лекарство, спрогнозировать будущее состояние и узнать, помогает ли лекарство от болезни или нет. Либо же можно использовать вероятность и, собрав кучу данных и проанализировав их, узнать, помогает ли лекарство или нет. Как человечество справляется с подобными вопросами мы и попытаемся узнать в этой статье. Конечно, информация, представленная здесь, не является истиной в последней инстанции и по конкретным вопросам лучше обратиться к специалистам или специализированной литературе.</p><p><a href="https://bayes.wustl.edu/etj/prob/book.pdf">Probability Theory: The Logic of Science</a></p><p><a href="https://berekuk.ru/blog/2017/11/08/true-scientific-method/">Настоящий научный подход</a></p><p><a href="https://habr.com/ru/post/435812/">Теория счастья. Статистика, как научный способ чего-либо не знать</a></p><p><a href="https://habr.com/ru/company/skillfactory/blog/526972/">Статистика в Data Science - исчерпывающий гид для амбициозных практиков ML</a></p><p><a href="https://wwnorton.com/books/Naked-Statistics/">Naked Statistics</a></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/ijcwuznmv9qpeumadzh7ca7sd5m.jpg"/></p><p>Для начала выделим области, где применима статистика. На самом деле сложные процессы, эффективно описываемые вероятностью, встречаются почти везде, включая, например, такие вопросы, как:</p><p>Образование:</p><p>Влияет ли увеличение финансирования школ на качество образования?</p><p>Эффективнее ли одна методика образования, чем другая?</p><p>Правда ли, что в одной стране образование лучше, чем в другой?</p><p>Преступность:</p><p>Влекут ли более жестокие наказания уменьшение преступности?</p><p>Как влияет смертная казнь на количество преступности?</p><p>Какие факторы влекут увеличение преступности?</p><p>Климат:</p><p>Какая завтра вероятность дождя?</p><p>Влечет ли увеличение отходов глобальное потепление?</p><p>Существует ли глобальное потепление?</p><p>Обыденные:</p><p>Способствует ли кофе развитию рака?</p><p>Способствует ли кофе борьбе с раком?</p><p>Полезно ли использовать зубную нить?</p><p>Честные ли вероятности попадания в XCOM: Enemy Unknown?</p><p>Какая ожидается цены на репу в Animal Crossing завтра?</p><p>Политические:</p><p>Нет ли фальшивых голосов на выборах?</p><p>Повлияло ли то или иное решение на экономику, и если да, то как: положительно или отрицательно?</p><p>Аграрные:</p><p>На какой земле лучше выращивать овощи?</p><p>В какой сезон продуктивнее растут овощи?</p><p>Эффективнее ли один удобритель, чем другой?</p><p>И так далее... Как видно, статистика имеет очень широкое применение даже вне лабораторий. Множество вопросов поддаются статистическому анализу, и потому эта область математики является одной из самых важных в прикладном плане. С появление компьютеров эта область разрослась еще больше, ибо теперь стало возможным исследовать большее количество данных и использовать вычислительно более сложные модели(например нейронные сети). Теперь не нужно делать кучу расчетов на бумажке и строить таблицы и вручную рисовать графики, чтобы сделать статистический анализ.</p><h1>Теория</h1><p>Для начала выведем некоторые важные формулы, необходимые нам для анализа. Изложение будет в простейшем виде и только для самых важных случаев, поэтому эту главу можно пропустить, если внутренняя математика вам неинтересна.</p><p>Тут не будет основ теории вероятности, с ними можно ознакомиться в любом начальном курсе по теории вероятности. Как и с матанализом.</p><p>Начнем с вывода некоторых распределений. Начнем с распределения Бернулли. Рассматривается последовательность независимых равновероятных экспериментов: броски монетки, кубика, вытаскивание шаров из мешка, любой другой игрушечный и натянутый на теорию пример. Понятно, что если вероятность успеха обозначить за $p$, то вероятность $m$ успехов среди $n$ испытаний в точности равна:</p><p>$$ mathbb{P}_n(m)=begin{pmatrix}n \mend{pmatrix}p^m(1-p)^{n-m} $$</p><p>Для больших $m$ и $n$ эту вероятность достаточно сложно посчитать, поэтому ее приближают другим распределением(которое явно проще посчитать). Это распределение называют нормальным и приближение будет выглядеть следующим образом:</p><p>$$ mathbb{P}_n(m)approxfrac{1}{sqrt{2pi np(1-p)}}e^{-frac{(m-np)^2}{2np(1-p)}} $$</p><p>Приближение действительно получается очень хорошим, если посмотреть на график:</p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled.png"/></p><p>Обозначая матожидание $mu=np$ и дисперсию $sigma=sqrt{np(1-p)}$, получаем более известный вид для нормального распределения:</p><p>$$ varphi(x)=frac{1}{sqrt{2pi}sigma}e^{-frac{(x-mu)^2}{2sigma^2}} $$</p><p>Это распределение очень часто используется, так как зачастую предположение, что что-либо распределено нормально, похоже на правду. Обозначается оно, как $mathcal{N}(mu, sigma^2)$. В классической статистике это распределение очень хорошо изучено и для анализа нам понадобится выяснять, как распределены матожидания и дисперсии выборок.</p><p>В результате анализа мы хотим узнать что-либо про очень большой набор обьектов: людей, транзакции, выпитые кружки кофе и т.д. Это множество обьектов называется <em>генеральной совокупностью</em> и обычно нет возможности собрать всю информацию про нее. Поэтому пользуются случайным набором из генеральной совокупности, называемым <em>выборкой</em>.</p><p>Далее, для изучения совокупности данных, исследуют некоторые величины, которые можно посчитать на основе выборке. Такие величины называют <em>статистиками</em> и самые частоиспользуемые статистики: матожидание(среднее значение) и дисперсия(мера разброса данных).</p><p>Формально, выборкой будем считать набор независимых случайных переменных $X<em>1,...,X</em>nsimmathcal{N}(mu,sigma^2)$. Тогда можно посчитать выборочное матожидание и дисперсию:</p><p>$$ mu=frac{1}{n}sumlimits<em>{i=1}^nX</em>inewline sigma^2=frac{1}{n}sumlimits<em>{i=1}^nX</em>i^2 $$</p><p>Для исследования этих статистик, из нормального распределения получают еще несколько распределений, необходимых для анализа:</p><ul><li>Квадрат дисперсии выборки $sigma^2$ имеет распределение $chi_n^2$ с $n$ степенями свободы.</li><li>Отношение квадратов двух дисперсий из двух выборок, размеров $n$ и $m$ соответственно, то есть $frac{sigma^2<em>n}{sigma^2</em>m}$ имеет распределение Фишера $F_{n,m}$ с $n,m$ степенями свободы.</li><li>Отношение матожидания к дисперсии, то есть $frac{mu}{sigma}$ имеет распределение стьюдента $t_n$ с $n$ степенями свободы.</li></ul><h3>Метод максимального правдоподобия</h3><p><a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum likelihood estimation</a></p><p>Отдельно, обсудим случай, что делать если параметры распределения выборки неизвестны. Например, мы знаем, что монетка выпадает одной стороной с вероятностью $p$, но саму эту вероятность мы точно не знаем. Как ее оценить?</p><p>Для этого есть прекрасный метод максимального правдоподобия. Начнем с формулы преподобного Байеса:</p><p>$$ p(theta|data)=frac{p(data|theta)p(theta)}{p(data)} $$</p><p>Где:</p><p>$theta$ - параметры распределения, которые мы хотим определить</p><p>$p(theta)$ - вероятностное распределение этих параметров, которое у нас есть <strong>до</strong> того, как мы провели эксперимент. Так как мы вообще ничего не знаем про параметры, можем принять $p(theta)=1$.</p><p>$p(data|theta)$ - вероятностное распределение данных эксперимента, если параметры равны $theta$. Считается оно следующим образом:</p><p>$$ p(data|theta)=prod<em>{i=1}^n f</em>theta(X_i) $$</p><p>где $f_theta$ - плотность распределения с параметрами $theta$.</p><p>$p(data)$ - константа, не зависящая от $theta$, которую нам даже не потребуется считать.</p><p>Хотим найти $theta$ больше всего "похожее на правду" среди всех возможных значений параметра $thetainTheta$. Формально:</p><p>$$ theta<em>{MAX}=argmax</em>{thetainTheta} p(theta|data)=argmax<em>{thetainTheta} p(data|theta)=argmax</em>{thetainTheta} prod<em>{i=1}^nf</em>theta(X_i) $$</p><p>Посчитав эту величину, мы и получим $theta$ больше всего(насколько позволяют данные) похожее на истинное значение.</p><h2>Статистические тесты</h2><p><a href="https://www.evanmiller.org/ab-testing/chi-squared.html">Chi-Squared Test</a></p><p><a href="https://medium.com/@vktech/practitioners-guide-to-statistical-tests-ed2d580ef04f">Practitioner's Guide to Statistical Tests</a></p><p><a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">Statistical hypothesis testing</a></p><p><a href="https://en.wikipedia.org/wiki/Statistic">Statistic</a></p><p><a href="https://en.wikipedia.org/wiki/Test_statistic">Test statistic</a></p><p><a href="https://en.wikipedia.org/wiki/Sign_test">Sign test</a></p><p><a href="https://habr.com/ru/company/stepic/blog/250527/">Основы статистики: просто о сложных формулах</a></p><p><a href="https://habr.com/ru/post/444124/">Как погрешность превращается в грех</a></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%201.png"/></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%202.png"/></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%203.png"/></p><h3>Если известно распределение</h3><p>Начнем опять-таки с формулы Байеса для вычисления вероятности гипотезы при известных данных:</p><p>$$ p(H|data)=frac{p(data|H)p(H)}{p(data)} $$</p><p>Часто эту формулу пишут в другом виде, не теряя ее основной смысл:</p><p>$$ p(H|data)propto p(data|H)p(H) $$</p><p>Суть которой в том, что мы имеем изначально какую то меру уверенности в гипотезе H, называемую априорной вероятностью. Затем после получения данных эксперимента, эти данные обновляются пропорционально вероятности этих данных: чем данные хуже описываются гипотезой, тем множитель $p(data|H)$ меньше, и наоборот.</p><p>Подход с использованием априорной вероятности часто критикуется из-за сложности обоснования конкретного вида $p(H)$. На практике же, при достаточном количестве данных и их "доказательной силе"(а конкретно значения $p(data|H)$), величина $p(H)$ играет малую роль. Так или иначе, часто ее принимают равной $p(H)=1$, в случае бесконечного числа гипотез, и $p(H)=frac{1}{n}$, если гипотез ровно $n$, что означает полную неопределенность насчет верности той или иной гипотезы. В этом случае формула выглядит еще проще:</p><p>$$ p(H|data)propto p(data|H) $$</p><h3>Если параметры распределения неизвестны</h3><h3>Если неизвестно распределение</h3><h2>Регрессия</h2><p>значимость регрессии</p><p>предсказание</p><p>[[data/static/old/someday_maybe/articles/Статья про исследования/_static/088342305000000331.pdf]]</p><p><a href="https://en.wikipedia.org/wiki/Regression_analysis">Regression analysis</a></p><p><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear regression</a></p><p><a href="https://en.wikipedia.org/wiki/General_linear_model">General linear model</a></p><h2>Вывод причинно-следственных связей</h2><p><a href="https://www.inference.vc/untitled/">ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus</a></p><p><a href="http://www.dagitty.net/">DAGitty - drawing and analyzing causal diagrams (DAGs)</a></p><p><a href="http://www.stat.columbia.edu/~cook/qr33.pdf"></a></p><p><a href="https://advances.sciencemag.org/content/5/11/eaau4996">Detecting and quantifying causal associations in large nonlinear time series datasets</a></p><p><a href="%D0%A1%D1%82%D0%B0%D1%82%D1%8C%D1%8F%20%D0%BF%D1%80%D0%BE%20224df.pdf">Арефьев.pdf</a></p><p><a href="https://en.wikipedia.org/wiki/Causal_inference">Causal inference</a></p><p><a href="https://habr.com/ru/company/vk/blog/518100/">Анализируем причинно-следственные связи метрик ВКонтакте</a></p><p><a href="https://medium.com/@itmo.mllab/causal-inference-in-the-context-of-social-network-metrics-analysis-edf541cccb51">Causal Inference in the Context of Social Network Metrics Analysis</a></p><h3>байесовские сети</h3><p><img alt="" src="https://image.prntscr.com/image/3Rbp3VgxTruggnvsNWh1mQ.png"/></p><h2>Научный метод</h2><h3>P-value и Null hypothesis</h3><p>Самой важной величиной при проверке статистических гипотез в классическом варианте является $p(data|H)$. Суть же проверки заключается в следующем: если вероятность получить подобные, либо еще более редкие, данные достаточно мала, то гипотеза $H$ скорее всего неверна. Кажется, как будто бы это логичный и верный подход.</p><p>Как же проводится проверка статистической гипотезы в классическом случае? Рассматриваются две гипотезы: "все как обычно", которая называется нулевой гипотезой и обозначается $H<em>0$, и альтернативная, по сути означающая "все не так просто", и обозначается она как $H</em>A$. После формулировки этих гипотез, выбирается некое значение $alpha$, называемое статистической значимостью. Это ни что иное, как ошибка первого рода, или вероятность отвергнуть нулевую гипотезу, когда на самом деле она верна. Обычно берется значение $0.05$, но иногда при возможности берется значение еще меньше.</p><p>Далее все просто: проводим эксперимент, получаем данные, считаем $p(data|H<em>0)$ и в силу того, что $p(H</em>0|data)approx p(data|H<em>0)$, судим о верности $H</em>0$ по величине $p(data|H)$.</p><p>В основном проверяют гипотезы трех видов относительно некой статистики распределения $theta$:</p><ul><li>$H<em>0$: "$theta=theta</em>0$"; $H<em>A$: "$thetaneqtheta</em>0$" или, что то же самое "$theta&lt;theta<em>0$ или $theta>theta</em>0$", "двусторонний тест"</li><li>$H<em>0$: "$theta=theta</em>0$"; $H<em>A$: "$theta>theta</em>0$", "правосторонний тест"</li><li>$H<em>0$: "$theta=theta</em>0$"; $H<em>A$: "$theta&lt;theta</em>0$", "левосторонний тест"</li></ul><p>На основе того, какая статистика нас интересуют, считают некоторую <em>тестовую статистику</em> $T$, которая имеет некое симметричное распределение $t$ и зависит от $theta<em>0$. Посчитав тестовую статистику по экспериментальным данным, мы получим некое значение $T</em>0$. И, наконец, в каждом из трех случаев, проверяется следующее утверждение:</p><ul><li>$p(|T|>T_0)&lt;alpha$</li><li>$p(T>T_0)&lt;alpha$</li><li>$p(T&lt;T_0)&lt;alpha$</li></ul><p>После проверки этого утверждения может быть два варианта:</p><ul><li>Утверждение верно: нулевая гипотеза $H<em>0$ отвергается, принимается $H</em>A$</li><li>Утверждение неверно: нулевую гипотезу $H_0$ нельзя отвергнуть на основе имеющихся данных</li></ul><p>Графически это можно изобразить следующим образом. Сначала нарисуем график распределения $t$ тестовой статистики $T$. Пусть $t=mathcal{N}(0,1)$ для примера. Затем выделяем промежутки $T<em>0$, для которых вышеуказанные неравенства выполняются. Эти промежутки называются <em>критическими регионами</em>. После подсчета тестовой статистики $T</em>0$, нулевая гипотеза отвергается, если $T<em>0$ попадает в этот критический регион. Граница критического региона называется <em>критическим значением</em> и обозначена как $T</em>gamma$. Критическое значение должно быть таким, чтобы выполнялось неравенство $mathbb{P}(T&lt;T_gamma)&lt;gamma$.</p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%204.png"/></p><p>Таким образом проверить вышеописанные неравенства можно двумя способами:</p><ul><li>посчитать значение распределения $t$ в точке $T_0$ и сравнить с необходимым значением</li><li>найти с помощью $alpha$ критическое значение $T<em>{кр}$ распределения $t$ и сравнить его с $T</em>0$</li></ul><p>В первом случае мы получим число, называющееся <em>p-value</em>, смысл которого следующий: это минимальное значение $alpha$, такое что с уже известным $T_0$ нулевая гипотеза будет принята. Обозначив p-value как $p$, получим, что неравенства эквивалентны следующим:</p><ul><li>$|p-frac{1}{2}| > frac{1-alpha}{2}$</li><li>$p > 1 - alpha$</li><li>$p &lt; alpha$</li></ul><p>&lt;aside> ‼️ считается, что связи нет, пока не доказано обратное</p><p>&lt;/aside></p><p>[[data/static/old/someday_maybe/articles/Статья про исследования/_static/A-Dirty-Dozen-Twelve-P-Value-Misconceptions.pdf]]</p><p><a href="https://lpgenerator.ru/blog/2016/07/11/podnimaya-zanaves-tajny-nad-p-znacheniyami-ili-kak-nauchitsya-lyubit-malye-dannye-small-data/">Поднимая "занавес тайны" над P-значениями, или Как научиться любить малые данные (Small Data)</a></p><p><a href="https://www.explainxkcd.com/wiki/index.php/892:_Null_Hypothesis">892: Null Hypothesis</a></p><h3>Коэффициент Байеса</h3><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%205.png"/></p><h3>Научный метод</h3><p><a href="https://andyjconnelly.wordpress.com/2017/02/13/plan-plan-and-plan-again-a-practical-guide-to-planning-experiments/amp/">Plan, plan and plan again: A practical guide to planning experiments</a></p><p>выделяется две тестовые группы: контрольная и (вторая)</p><p>контрольная и (вторая) группы должны быть случайно перемешаны</p><p><a href="https://lpgenerator.ru/blog/2020/04/20/chek-list-po-split-testirovaniyu-15-shagov-do-vo-vremya-i-posle/">Чек-лист по сплит-тестированию: 15 шагов до, во время и после</a></p><p><a href="https://habr.com/ru/company/jugru/blog/358104/">Ваши A/B-тесты сломаны</a></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%206.png"/></p><h2>Частые ошибки в статистических исследованиях</h2><h3>Ошибка базового процента</h3><p><a href="https://ru.wikipedia.org/wiki/Ошибка_базового_процента">Ошибка базового процента - Википедия</a></p><p><a href="https://www.explainxkcd.com/wiki/index.php/1102:_Fastest-Growing">1102: Fastest-Growing</a></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%207.png"/></p><p>сделать какую-нибудь статистическую поправку и посчитать "настоящее" p-value</p><h3>correlation does not imply causation</h3><p><a href="https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation">Correlation does not imply causation - Wikipedia</a></p><p><a href="https://en.wikipedia.org/wiki/Confounding">Confounding - Wikipedia</a></p><p>A коррелирует с B означает одно из</p><p>A -> B</p><p>B -> A</p><p>A &lt;- C -> B</p><p>совпадение</p><h3>совпадения</h3><p>парадокс дней рождения, хеши</p><p>корреляция несвязанных между собой данных</p><p>nn attack</p><h3>P-hacking</h3><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%208.png"/></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%209.png"/></p><p><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%2010.png"/></p><p><a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">Multiple comparisons problem - Wikipedia</a></p><p><a href="https://en.wikipedia.org/wiki/Data_dredging">Data dredging</a></p><h3>Ложная корреляция</h3><p><a href="http://tylervigen.com/spurious-correlations">15 Insane Things That Correlate With Each Other</a></p><p>Positive correlation<img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/72890555_10162293732195577_7970207155200458752_o.png"/></p><p>Negative correlation<img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/F8pz8kLM_WQ.jpg"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/73071761_10162362388780577_8409134816938688512_o.png"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/71829670_10162216134000577_838172651749900288_o.jpg"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/73713659_10162327980755577_1278124487094566912_o.png"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/72611582_10162262136285577_4776040539805974528_o.jpg"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/71677030_10162192980945577_7361797571406200832_o.png"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Qvq3_ZPdxrM.jpg"/><img alt="" src="data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/74892367_10162439362290577_8237771093616623616_o.png"/></p><h1>Практика</h1><h2>Нечестная монетка</h2><p><a href="https://izbicki.me/blog/how-to-create-an-unfair-coin-and-prove-it-with-math.html">How to create an unfair coin and prove it with math</a></p><p><a href="https://izbicki.me/blog/how-to-cheat-at-settlers-of-catan-by-loading-the-dice-and-prove-it-with-p-values.html">how to cheat at settlers by loading the dice</a></p><h2>Вероятности попадания в XCOM</h2><p>проверка на честность вероятностей в XCOM</p><p>Регрессия для выяснения в какую сторону отклонен рандом(если отклонен)</p><p><a href="https://www.reddit.com/r/XCOM2/comments/842v7f/xcom2_probability/">XCOM2 Probability?</a></p><p><a href="https://sinepost.wordpress.com/2012/10/26/probability-in-games-xcom/">Probability in Games: XCOM</a></p><p><a href="http://www.win-vector.com/blog/2012/12/how-to-test-xcom-dice-rolls-for-fairness/">How to test XCOM "dice rolls" for fairness</a></p><h2>Читерство в игре Minecraft</h2><p><a href="https://www.youtube.com/watch?v=K1DMCWVhZXs">Спидран по Майнкрафту. Крупнейший скандал</a></p><p><a href="https://mcspeedrun.com/dream.pdf"></a></p><p><a href="https://drive.google.com/file/d/1yfLURFdDhMfrvI2cFMdYM8f_M_IRoAlM/view">Dream<em>Minecraft</em>Report.pdf</a></p><p><a href="https://mcspeedrun.com/dream/rebuttal.pdf"></a></p><p><a href="https://www.reddit.com/r/statistics/comments/kiqosv/d_accused_minecraft_speedrunner_who_was_caught/ggse2er/?utm_source=share&utm_medium=web2x&context=3">r/statistics - Comment by u/mfb- on "[D] Accused minecraft speedrunner who was caught using statistic responded back with more statistic."</a></p><p><a href="https://docs.google.com/document/u/0/d/1OlvAjAI9X8QqNY8Z4od-pdsCFETNVqQG1-hHFjFo7wo/mobilebasic">Sswiss mathematics student On Dream Stats</a></p><h2>Колесо HPG 2</h2><p>однородность колеса в хпг</p><p><a href="https://colab.research.google.com/drive/1hnZMrAVub5J_dsJdFSG0MczPdL6y6Z_9?usp=sharing">Google Colaboratory</a></p><h2>Вредит ли курение здоровью</h2><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2038856/?page=1">Smoking and Carcinoma of the Lung</a></p><p>Smoking and Carcinoma of the Lung</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2085438/?page=1">The Mortality of Doctors in Relation to Their Smoking Habits</a></p><p>The Mortality of Doctors in Relation to Their Smoking Habits</p><p><a href="https://priceonomics.com/why-the-father-of-modern-statistics-didnt-believe/">Why the Father of Modern Statistics Didn't Believe Smoking Caused Cancer</a></p><h2>Выборы</h2><p><a href="https://storm100.livejournal.com/8051640.html">Голосование завершилось! Весь процесс был честным, безопасным и прозрачным</a></p><p><a href="https://www.bbc.com/russian/live/features-53218582">Голосование по поправкам к Конституции: где проголосовали "против" - Новости на русском языке</a></p><p><a href="https://paperpaper.ru/kak-prohodilo-golosovanie-po-popravk/">Как проходило голосование по поправкам в Петербурге</a></p><p><a href="https://www.golosinfo.org/articles/144499?utm_source=vk.com&utm_medium=social&utm_campaign=na-uchastke-1086-v-podmoskovnom-koroleve">Обнулительный кордебалет, или Что могут один наблюдатель и 44 избирателя</a></p><p><a href="https://vk.com/wall702213_4321">Хорошо на Руси рисуют! | Andrey Smolensky | VK</a></p><h2>Статистика коровавируса</h2><p><a href="https://medium.com/@innersun/как-увидеть-эпидемию-если-её-старательно-прячут-опыт-5-регионов-10f6da83e5a8">Как увидеть эпидемию, если её старательно прячут. Опыт 5 регионов</a></p><p><a href="https://medium.com/@barouh/что-беспокоит-россиян-или-как-проверить-официальную-статистику-коронавируса-9e5f58815c0d">Что беспокоит россиян, или как проверить официальную статистику коронавируса</a></p><h2>Прием LSD в лечебных целях</h2><p><a href="https://www.gwern.net/LSD-microdosing">LSD microdosing RCT</a></p><h1>Заметки</h1><ul><li>написать про латинский квадрат (мб в научном методе)</li><li>написать про EDA / описательную статистику</li><li>написать про манипуляции со статистикой, использование графиков для этого</li></ul><p>  <br/>    <a href="https://vas3k.ru/blog/379/">Почему 119% статистики в интернете - ложь</a>  <br/></p><ul><li>написать про роль и применение машинного обучения</li><li>считать для примеров и pvalue и коэффициент Байеса</li><li>прикрепить ссылку на код: блокнот с графиками и вычислениями</li><li>перепроверить формулы и расчеты</li><li>кинуть Ярославу на перечитку</li></ul><p><a href="https://colab.research.google.com/drive/1hnZMrAVub5J_dsJdFSG0MczPdL6y6Z_9?usp=sharing">Google Colaboratory</a></p><p><a href="https://github.com/statsmodels/statsmodels">statsmodels/statsmodels</a></p><p><a href="https://pythonhosted.org/pyDOE/index.html">pyDOE: The experimental design package for python - pyDOE 0.3.6 documentation</a></p><p><a href="https://probmods.org/">Probabilistic Models of Cognition</a></p><p><a href="https://www.getguesstimate.com/models">Guesstimate | A Spreadsheet for the Uncertain</a></p><p><a href="https://statsim.com/">StatSim - Statistical Simulations &amp; Bayesian Inference</a></p><p><a href="http://webppl.org/">WebPPL - probabilistic programming for the web</a></p><p><a href="https://habr.com/en/company/skillfactory/blog/570736/">Чем машинное обучение отличается от статистики на самом деле</a></p><p><a href="https://www.nature.com/articles/nmeth.4642">Statistics versus machine learning - Nature Methods</a></p><p><a href="https://habr.com/en/company/glowbyte/blog/569970/"></a></p><p>[[data/static/old/someday_maybe/articles/Статья про исследования/_static/Ася Казанцева В интернете кто-то неправ! Научные исследования спорных вопросов.pdf]]</p><p><a href="https://probmods.org/">Probabilistic Models of Cognition</a></p><p>[[data/static/old/someday_maybe/articles/Статья про исследования/_static/Как из наблюдаемых корреляций оценить причинно-следственные связи? Сравнение подходов, используемых в экономике и компьютерных науках.pdf]]</p><p>[[data/probabilistic tests]]</p>
    </article>

    <footer>
    <p>
        Sistine is a project by
        <a href="https://thesephist.com/" target="_blank">Linus</a>
        built with
        <a href="https://dotink.co/" target="_blank">Ink</a>.
    </p>
</footer>

</main>

<script src="/js/main.js"></script>

</body>
