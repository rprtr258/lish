#article

[[data/Изучить статистику]]

# А главное зачем

Статистика не так уж далека от жизни. С ее помощью исследуют что-либо, что сложно описать и проще использовать вероятностные методы. Например, для исследования эффективности лекарства, можно проследить все химически и биологические реакции организма на это лекарство, спрогнозировать будущее состояние и узнать, помогает ли лекарство от болезни или нет. Либо же можно использовать вероятность и, собрав кучу данных и проанализировав их, узнать, помогает ли лекарство или нет. Как человечество справляется с подобными вопросами мы и попытаемся узнать в этой статье. Конечно, информация, представленная здесь, не является истиной в последней инстанции и по конкретным вопросам лучше обратиться к специалистам или специализированной литературе.

[Probability Theory: The Logic of Science](https://bayes.wustl.edu/etj/prob/book.pdf)

[Настоящий научный подход](https://berekuk.ru/blog/2017/11/08/true-scientific-method/)

[Теория счастья. Статистика, как научный способ чего-либо не знать](https://habr.com/ru/post/435812/)

[Статистика в Data Science - исчерпывающий гид для амбициозных практиков ML](https://habr.com/ru/company/skillfactory/blog/526972/)

[Naked Statistics](https://wwnorton.com/books/Naked-Statistics/)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/ijcwuznmv9qpeumadzh7ca7sd5m.jpg)

Для начала выделим области, где применима статистика. На самом деле сложные процессы, эффективно описываемые вероятностью, встречаются почти везде, включая, например, такие вопросы, как:

Образование:

Влияет ли увеличение финансирования школ на качество образования?

Эффективнее ли одна методика образования, чем другая?

Правда ли, что в одной стране образование лучше, чем в другой?

Преступность:

Влекут ли более жестокие наказания уменьшение преступности?

Как влияет смертная казнь на количество преступности?

Какие факторы влекут увеличение преступности?

Климат:

Какая завтра вероятность дождя?

Влечет ли увеличение отходов глобальное потепление?

Существует ли глобальное потепление?

Обыденные:

Способствует ли кофе развитию рака?

Способствует ли кофе борьбе с раком?

Полезно ли использовать зубную нить?

Честные ли вероятности попадания в XCOM: Enemy Unknown?

Какая ожидается цены на репу в Animal Crossing завтра?

Политические:

Нет ли фальшивых голосов на выборах?

Повлияло ли то или иное решение на экономику, и если да, то как: положительно или отрицательно?

Аграрные:

На какой земле лучше выращивать овощи?

В какой сезон продуктивнее растут овощи?

Эффективнее ли один удобритель, чем другой?

И так далее... Как видно, статистика имеет очень широкое применение даже вне лабораторий. Множество вопросов поддаются статистическому анализу, и потому эта область математики является одной из самых важных в прикладном плане. С появление компьютеров эта область разрослась еще больше, ибо теперь стало возможным исследовать большее количество данных и использовать вычислительно более сложные модели(например нейронные сети). Теперь не нужно делать кучу расчетов на бумажке и строить таблицы и вручную рисовать графики, чтобы сделать статистический анализ.

# Теория

Для начала выведем некоторые важные формулы, необходимые нам для анализа. Изложение будет в простейшем виде и только для самых важных случаев, поэтому эту главу можно пропустить, если внутренняя математика вам неинтересна.

Тут не будет основ теории вероятности, с ними можно ознакомиться в любом начальном курсе по теории вероятности. Как и с матанализом.

Начнем с вывода некоторых распределений. Начнем с распределения Бернулли. Рассматривается последовательность независимых равновероятных экспериментов: броски монетки, кубика, вытаскивание шаров из мешка, любой другой игрушечный и натянутый на теорию пример. Понятно, что если вероятность успеха обозначить за $p$, то вероятность $m$ успехов среди $n$ испытаний в точности равна:

$$
\mathbb{P}_n(m)=\begin{pmatrix}n \\m\end{pmatrix}p^m(1-p)^{n-m}
$$

Для больших $m$ и $n$ эту вероятность достаточно сложно посчитать, поэтому ее приближают другим распределением(которое явно проще посчитать). Это распределение называют нормальным и приближение будет выглядеть следующим образом:

$$
\mathbb{P}_n(m)\approx\frac{1}{\sqrt{2\pi np(1-p)}}e^{-\frac{(m-np)^2}{2np(1-p)}}
$$

Приближение действительно получается очень хорошим, если посмотреть на график:

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled.png)

Обозначая матожидание $\mu=np$ и дисперсию $\sigma=\sqrt{np(1-p)}$, получаем более известный вид для нормального распределения:

$$
\varphi(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

Это распределение очень часто используется, так как зачастую предположение, что что-либо распределено нормально, похоже на правду. Обозначается оно, как $\mathcal{N}(\mu, \sigma^2)$. В классической статистике это распределение очень хорошо изучено и для анализа нам понадобится выяснять, как распределены матожидания и дисперсии выборок.

В результате анализа мы хотим узнать что-либо про очень большой набор обьектов: людей, транзакции, выпитые кружки кофе и т.д. Это множество обьектов называется *генеральной совокупностью* и обычно нет возможности собрать всю информацию про нее. Поэтому пользуются случайным набором из генеральной совокупности, называемым *выборкой*.

Далее, для изучения совокупности данных, исследуют некоторые величины, которые можно посчитать на основе выборке. Такие величины называют *статистиками* и самые частоиспользуемые статистики: матожидание(среднее значение) и дисперсия(мера разброса данных).

Формально, выборкой будем считать набор независимых случайных переменных $X_1,...,X_n\sim\mathcal{N}(\mu,\sigma^2)$. Тогда можно посчитать выборочное матожидание и дисперсию:

$$
\mu=\frac{1}{n}\sum\limits_{i=1}^nX_i\newline
\sigma^2=\frac{1}{n}\sum\limits_{i=1}^nX_i^2
$$

Для исследования этих статистик, из нормального распределения получают еще несколько распределений, необходимых для анализа:

- Квадрат дисперсии выборки $\sigma^2$ имеет распределение $\chi_n^2$ с $n$ степенями свободы.
- Отношение квадратов двух дисперсий из двух выборок, размеров $n$ и $m$ соответственно, то есть $\frac{\sigma^2_n}{\sigma^2_m}$ имеет распределение Фишера $F_{n,m}$ с $n,m$ степенями свободы.
- Отношение матожидания к дисперсии, то есть $\frac{\mu}{\sigma}$ имеет распределение стьюдента $t_n$ с $n$ степенями свободы.

### Метод максимального правдоподобия

[Maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)

Отдельно, обсудим случай, что делать если параметры распределения выборки неизвестны. Например, мы знаем, что монетка выпадает одной стороной с вероятностью $p$, но саму эту вероятность мы точно не знаем. Как ее оценить?

Для этого есть прекрасный метод максимального правдоподобия. Начнем с формулы преподобного Байеса:

$$
p(\theta|data)=\frac{p(data|\theta)p(\theta)}{p(data)}
$$

Где:

$\theta$ - параметры распределения, которые мы хотим определить

$p(\theta)$ - вероятностное распределение этих параметров, которое у нас есть **до** того, как мы провели эксперимент. Так как мы вообще ничего не знаем про параметры, можем принять $p(\theta)=1$.

$p(data|\theta)$ - вероятностное распределение данных эксперимента, если параметры равны $\theta$. Считается оно следующим образом:

$$
p(data|\theta)=\prod_{i=1}^n f_\theta(X_i)
$$

где $f_\theta$ - плотность распределения с параметрами $\theta$.

$p(data)$ - константа, не зависящая от $\theta$, которую нам даже не потребуется считать.

Хотим найти $\theta$ больше всего "похожее на правду" среди всех возможных значений параметра $\theta\in\Theta$. Формально:

$$
\theta_{MAX}=\argmax_{\theta\in\Theta} p(\theta|data)=\argmax_{\theta\in\Theta} p(data|\theta)=\argmax_{\theta\in\Theta} \prod_{i=1}^nf_\theta(X_i)
$$

Посчитав эту величину, мы и получим $\theta$ больше всего(насколько позволяют данные) похожее на истинное значение.

## Статистические тесты

[Chi-Squared Test](https://www.evanmiller.org/ab-testing/chi-squared.html)

[Practitioner's Guide to Statistical Tests](https://medium.com/@vktech/practitioners-guide-to-statistical-tests-ed2d580ef04f)

[Statistical hypothesis testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)

[Statistic](https://en.wikipedia.org/wiki/Statistic)

[Test statistic](https://en.wikipedia.org/wiki/Test_statistic)

[Sign test](https://en.wikipedia.org/wiki/Sign_test)

[Основы статистики: просто о сложных формулах](https://habr.com/ru/company/stepic/blog/250527/)

[Как погрешность превращается в грех](https://habr.com/ru/post/444124/)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%201.png)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%202.png)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%203.png)

### Если известно распределение

Начнем опять-таки с формулы Байеса для вычисления вероятности гипотезы при известных данных:

$$
p(H|data)=\frac{p(data|H)p(H)}{p(data)}
$$

Часто эту формулу пишут в другом виде, не теряя ее основной смысл:

$$
p(H|data)\propto p(data|H)p(H)
$$

Суть которой в том, что мы имеем изначально какую то меру уверенности в гипотезе H, называемую априорной вероятностью. Затем после получения данных эксперимента, эти данные обновляются пропорционально вероятности этих данных: чем данные хуже описываются гипотезой, тем множитель $p(data|H)$ меньше, и наоборот.

Подход с использованием априорной вероятности часто критикуется из-за сложности обоснования конкретного вида $p(H)$. На практике же, при достаточном количестве данных и их "доказательной силе"(а конкретно значения $p(data|H)$), величина $p(H)$ играет малую роль. Так или иначе, часто ее принимают равной $p(H)=1$, в случае бесконечного числа гипотез, и $p(H)=\frac{1}{n}$, если гипотез ровно $n$, что означает полную неопределенность насчет верности той или иной гипотезы. В этом случае формула выглядит еще проще:

$$
p(H|data)\propto p(data|H)
$$

### Если параметры распределения неизвестны

### Если неизвестно распределение

## Регрессия

значимость регрессии

предсказание

[[data/static/old/someday_maybe/articles/Статья про исследования/_static/088342305000000331.pdf]]

[Regression analysis](https://en.wikipedia.org/wiki/Regression_analysis)

[Linear regression](https://en.wikipedia.org/wiki/Linear_regression)

[General linear model](https://en.wikipedia.org/wiki/General_linear_model)

## Вывод причинно-следственных связей

[ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus](https://www.inference.vc/untitled/)

[DAGitty - drawing and analyzing causal diagrams (DAGs)](http://www.dagitty.net/)

[](http://www.stat.columbia.edu/~cook/qr33.pdf)

[Detecting and quantifying causal associations in large nonlinear time series datasets](https://advances.sciencemag.org/content/5/11/eaau4996)

[Арефьев.pdf](%D0%A1%D1%82%D0%B0%D1%82%D1%8C%D1%8F%20%D0%BF%D1%80%D0%BE%20224df.pdf)

[Causal inference](https://en.wikipedia.org/wiki/Causal_inference)

[Анализируем причинно-следственные связи метрик ВКонтакте](https://habr.com/ru/company/vk/blog/518100/)

[Causal Inference in the Context of Social Network Metrics Analysis](https://medium.com/@itmo.mllab/causal-inference-in-the-context-of-social-network-metrics-analysis-edf541cccb51)

### байесовские сети

![](https://image.prntscr.com/image/3Rbp3VgxTruggnvsNWh1mQ.png)

## Научный метод

### P-value и Null hypothesis

Самой важной величиной при проверке статистических гипотез в классическом варианте является $p(data|H)$. Суть же проверки заключается в следующем: если вероятность получить подобные, либо еще более редкие, данные достаточно мала, то гипотеза $H$ скорее всего неверна. Кажется, как будто бы это логичный и верный подход.

Как же проводится проверка статистической гипотезы в классическом случае? Рассматриваются две гипотезы: "все как обычно", которая называется нулевой гипотезой и обозначается $H_0$, и альтернативная, по сути означающая "все не так просто", и обозначается она как $H_A$. После формулировки этих гипотез, выбирается некое значение $\alpha$, называемое статистической значимостью. Это ни что иное, как ошибка первого рода, или вероятность отвергнуть нулевую гипотезу, когда на самом деле она верна. Обычно берется значение $0.05$, но иногда при возможности берется значение еще меньше.

Далее все просто: проводим эксперимент, получаем данные, считаем $p(data|H_0)$ и в силу того, что $p(H_0|data)\approx p(data|H_0)$, судим о верности $H_0$ по величине $p(data|H)$.

В основном проверяют гипотезы трех видов относительно некой статистики распределения $\theta$:

- $H_0$: "$\theta=\theta_0$"; $H_A$: "$\theta\neq\theta_0$" или, что то же самое "$\theta<\theta_0$ или $\theta>\theta_0$", "двусторонний тест"
- $H_0$: "$\theta=\theta_0$"; $H_A$: "$\theta>\theta_0$", "правосторонний тест"
- $H_0$: "$\theta=\theta_0$"; $H_A$: "$\theta<\theta_0$", "левосторонний тест"

На основе того, какая статистика нас интересуют, считают некоторую *тестовую статистику* $T$, которая имеет некое симметричное распределение $t$ и зависит от $\theta_0$. Посчитав тестовую статистику по экспериментальным данным, мы получим некое значение $T_0$. И, наконец, в каждом из трех случаев, проверяется следующее утверждение:

- $p(|T|>T_0)<\alpha$
- $p(T>T_0)<\alpha$
- $p(T<T_0)<\alpha$

После проверки этого утверждения может быть два варианта:

- Утверждение верно: нулевая гипотеза $H_0$ отвергается, принимается $H_A$
- Утверждение неверно: нулевую гипотезу $H_0$ нельзя отвергнуть на основе имеющихся данных

Графически это можно изобразить следующим образом. Сначала нарисуем график распределения $t$ тестовой статистики $T$. Пусть $t=\mathcal{N}(0,1)$ для примера. Затем выделяем промежутки $T_0$, для которых вышеуказанные неравенства выполняются. Эти промежутки называются *критическими регионами*. После подсчета тестовой статистики $T_0$, нулевая гипотеза отвергается, если $T_0$ попадает в этот критический регион. Граница критического региона называется *критическим значением* и обозначена как $T_\gamma$. Критическое значение должно быть таким, чтобы выполнялось неравенство $\mathbb{P}(T<T_\gamma)<\gamma$.

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%204.png)

Таким образом проверить вышеописанные неравенства можно двумя способами:

- посчитать значение распределения $t$ в точке $T_0$ и сравнить с необходимым значением
- найти с помощью $\alpha$ критическое значение $T_{кр}$ распределения $t$ и сравнить его с $T_0$

В первом случае мы получим число, называющееся *p-value*, смысл которого следующий: это минимальное значение $\alpha$, такое что с уже известным $T_0$ нулевая гипотеза будет принята. Обозначив p-value как $p$, получим, что неравенства эквивалентны следующим:

- $|p-\frac{1}{2}| > \frac{1-\alpha}{2}$
- $p > 1 - \alpha$
- $p < \alpha$

<aside>
‼️ считается, что связи нет, пока не доказано обратное

</aside>

[[data/static/old/someday_maybe/articles/Статья про исследования/_static/A-Dirty-Dozen-Twelve-P-Value-Misconceptions.pdf]]

[Поднимая "занавес тайны" над P-значениями, или Как научиться любить малые данные (Small Data)](https://lpgenerator.ru/blog/2016/07/11/podnimaya-zanaves-tajny-nad-p-znacheniyami-ili-kak-nauchitsya-lyubit-malye-dannye-small-data/)

[892: Null Hypothesis](https://www.explainxkcd.com/wiki/index.php/892:_Null_Hypothesis)

### Коэффициент Байеса

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%205.png)

### Научный метод

[Plan, plan and plan again: A practical guide to planning experiments](https://andyjconnelly.wordpress.com/2017/02/13/plan-plan-and-plan-again-a-practical-guide-to-planning-experiments/amp/)

выделяется две тестовые группы: контрольная и (вторая)

контрольная и (вторая) группы должны быть случайно перемешаны

[Чек-лист по сплит-тестированию: 15 шагов до, во время и после](https://lpgenerator.ru/blog/2020/04/20/chek-list-po-split-testirovaniyu-15-shagov-do-vo-vremya-i-posle/)

[Ваши A/B-тесты сломаны](https://habr.com/ru/company/jugru/blog/358104/)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%206.png)

## Частые ошибки в статистических исследованиях

### Ошибка базового процента

[Ошибка базового процента - Википедия](https://ru.wikipedia.org/wiki/Ошибка_базового_процента)

[1102: Fastest-Growing](https://www.explainxkcd.com/wiki/index.php/1102:_Fastest-Growing)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%207.png)

сделать какую-нибудь статистическую поправку и посчитать "настоящее" p-value

### correlation does not imply causation

[Correlation does not imply causation - Wikipedia](https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation)

[Confounding - Wikipedia](https://en.wikipedia.org/wiki/Confounding)

A коррелирует с B означает одно из

A -> B

B -> A

A <- C -> B

совпадение

### совпадения

парадокс дней рождения, хеши

корреляция несвязанных между собой данных

nn attack

### P-hacking

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%208.png)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%209.png)

![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Untitled%2010.png)

[Multiple comparisons problem - Wikipedia](https://en.wikipedia.org/wiki/Multiple_comparisons_problem)

[Data dredging](https://en.wikipedia.org/wiki/Data_dredging)

### Ложная корреляция

[15 Insane Things That Correlate With Each Other](http://tylervigen.com/spurious-correlations)

Positive correlation
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/72890555_10162293732195577_7970207155200458752_o.png)

Negative correlation
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/F8pz8kLM_WQ.jpg)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/73071761_10162362388780577_8409134816938688512_o.png)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/71829670_10162216134000577_838172651749900288_o.jpg)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/73713659_10162327980755577_1278124487094566912_o.png)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/72611582_10162262136285577_4776040539805974528_o.jpg)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/71677030_10162192980945577_7361797571406200832_o.png)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/Qvq3_ZPdxrM.jpg)
![](data/static/old/someday_maybe/articles/Статья%20про%20исследования/_static/74892367_10162439362290577_8237771093616623616_o.png)

# Практика

## Нечестная монетка

[How to create an unfair coin and prove it with math](https://izbicki.me/blog/how-to-create-an-unfair-coin-and-prove-it-with-math.html)

[how to cheat at settlers by loading the dice](https://izbicki.me/blog/how-to-cheat-at-settlers-of-catan-by-loading-the-dice-and-prove-it-with-p-values.html)

## Вероятности попадания в XCOM

проверка на честность вероятностей в XCOM

Регрессия для выяснения в какую сторону отклонен рандом(если отклонен)

[XCOM2 Probability?](https://www.reddit.com/r/XCOM2/comments/842v7f/xcom2_probability/)

[Probability in Games: XCOM](https://sinepost.wordpress.com/2012/10/26/probability-in-games-xcom/)

[How to test XCOM "dice rolls" for fairness](http://www.win-vector.com/blog/2012/12/how-to-test-xcom-dice-rolls-for-fairness/)

## Читерство в игре Minecraft

[Спидран по Майнкрафту. Крупнейший скандал](https://www.youtube.com/watch?v=K1DMCWVhZXs)

[](https://mcspeedrun.com/dream.pdf)

[Dream_Minecraft_Report.pdf](https://drive.google.com/file/d/1yfLURFdDhMfrvI2cFMdYM8f_M_IRoAlM/view)

[](https://mcspeedrun.com/dream/rebuttal.pdf)

[r/statistics - Comment by u/mfb- on "[D] Accused minecraft speedrunner who was caught using statistic responded back with more statistic."](https://www.reddit.com/r/statistics/comments/kiqosv/d_accused_minecraft_speedrunner_who_was_caught/ggse2er/?utm_source=share&utm_medium=web2x&context=3)

[Sswiss mathematics student On Dream Stats](https://docs.google.com/document/u/0/d/1OlvAjAI9X8QqNY8Z4od-pdsCFETNVqQG1-hHFjFo7wo/mobilebasic)

## Колесо HPG 2

однородность колеса в хпг

[Google Colaboratory](https://colab.research.google.com/drive/1hnZMrAVub5J_dsJdFSG0MczPdL6y6Z_9?usp=sharing)

## Вредит ли курение здоровью

[Smoking and Carcinoma of the Lung](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2038856/?page=1)

Smoking and Carcinoma of the Lung

[The Mortality of Doctors in Relation to Their Smoking Habits](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2085438/?page=1)

The Mortality of Doctors in Relation to Their Smoking Habits

[Why the Father of Modern Statistics Didn't Believe Smoking Caused Cancer](https://priceonomics.com/why-the-father-of-modern-statistics-didnt-believe/)

## Выборы

[Голосование завершилось! Весь процесс был честным, безопасным и прозрачным](https://storm100.livejournal.com/8051640.html)

[Голосование по поправкам к Конституции: где проголосовали "против" - Новости на русском языке](https://www.bbc.com/russian/live/features-53218582)

[Как проходило голосование по поправкам в Петербурге](https://paperpaper.ru/kak-prohodilo-golosovanie-po-popravk/)

[Обнулительный кордебалет, или Что могут один наблюдатель и 44 избирателя](https://www.golosinfo.org/articles/144499?utm_source=vk.com&utm_medium=social&utm_campaign=na-uchastke-1086-v-podmoskovnom-koroleve)

[Хорошо на Руси рисуют! | Andrey Smolensky | VK](https://vk.com/wall702213_4321)

## Статистика коровавируса

[Как увидеть эпидемию, если её старательно прячут. Опыт 5 регионов](https://medium.com/@innersun/как-увидеть-эпидемию-если-её-старательно-прячут-опыт-5-регионов-10f6da83e5a8)

[Что беспокоит россиян, или как проверить официальную статистику коронавируса](https://medium.com/@barouh/что-беспокоит-россиян-или-как-проверить-официальную-статистику-коронавируса-9e5f58815c0d)

## Прием LSD в лечебных целях

[LSD microdosing RCT](https://www.gwern.net/LSD-microdosing)

# Заметки

- написать про латинский квадрат (мб в научном методе)
- написать про EDA / описательную статистику
- написать про манипуляции со статистикой, использование графиков для этого
    
    [Почему 119% статистики в интернете - ложь](https://vas3k.ru/blog/379/)
    
- написать про роль и применение машинного обучения
- считать для примеров и pvalue и коэффициент Байеса
- прикрепить ссылку на код: блокнот с графиками и вычислениями
- перепроверить формулы и расчеты
- кинуть Ярославу на перечитку

[Google Colaboratory](https://colab.research.google.com/drive/1hnZMrAVub5J_dsJdFSG0MczPdL6y6Z_9?usp=sharing)

[statsmodels/statsmodels](https://github.com/statsmodels/statsmodels)

[pyDOE: The experimental design package for python - pyDOE 0.3.6 documentation](https://pythonhosted.org/pyDOE/index.html)

[Probabilistic Models of Cognition](https://probmods.org/)

[Guesstimate | A Spreadsheet for the Uncertain](https://www.getguesstimate.com/models)

[StatSim - Statistical Simulations & Bayesian Inference](https://statsim.com/)

[WebPPL - probabilistic programming for the web](http://webppl.org/)

[Чем машинное обучение отличается от статистики на самом деле](https://habr.com/en/company/skillfactory/blog/570736/)

[Statistics versus machine learning - Nature Methods](https://www.nature.com/articles/nmeth.4642)

[](https://habr.com/en/company/glowbyte/blog/569970/)

[[data/static/old/someday_maybe/articles/Статья про исследования/_static/Ася Казанцева В интернете кто-то неправ! Научные исследования спорных вопросов.pdf]]

[Probabilistic Models of Cognition](https://probmods.org/)

[[data/static/old/someday_maybe/articles/Статья про исследования/_static/Как из наблюдаемых корреляций оценить причинно-следственные связи? Сравнение подходов, используемых в экономике и компьютерных науках.pdf]]



[[data/probabilistic tests]]